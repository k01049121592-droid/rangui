import streamlit as st
import pandas as pd
import re
from pathlib import Path

# ============================================================================
# í˜ì´ì¦ˆ 1: ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
# ============================================================================

@st.cache_data
def load_raw_data(file_path: str) -> pd.DataFrame:
    """
    CSV íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        file_path: CSV íŒŒì¼ ê²½ë¡œ
        
    Returns:
        ì›ë³¸ DataFrame
    """
    try:
        # UTF-8ë¡œ ë¨¼ì € ì‹œë„
        df = pd.read_csv(file_path, encoding='utf-8')
    except UnicodeDecodeError:
        # CP949ë¡œ ì¬ì‹œë„
        df = pd.read_csv(file_path, encoding='cp949')
    
    return df


def clean_time_slot(time_str: str) -> str:
    """
    ì‹œê°„ëŒ€ ë¬¸ìì—´ì„ ì •ê·œí™”í•©ë‹ˆë‹¤.
    
    ì˜ˆ: "5ì‹œ30ë¶„" â†’ "05:30", "12ì‹œ00ë¶„" â†’ "12:00"
    
    Args:
        time_str: ì›ë³¸ ì‹œê°„ ë¬¸ìì—´
        
    Returns:
        ì •ê·œí™”ëœ ì‹œê°„ ë¬¸ìì—´ (HH:MM)
    """
    # "5ì‹œ30ë¶„" í˜•íƒœì—ì„œ ìˆ«ì ì¶”ì¶œ
    match = re.match(r'(\d+)ì‹œ(\d+)ë¶„', time_str)
    if match:
        hour = match.group(1).zfill(2)  # 2ìë¦¬ë¡œ íŒ¨ë”©
        minute = match.group(2).zfill(2)
        return f"{hour}:{minute}"
    return time_str


def clean_congestion(value) -> float:
    """
    í˜¼ì¡ë„ ê°’ì„ ì •ë¦¬í•©ë‹ˆë‹¤.
    
    - ê³µë°± ì œê±°
    - float íƒ€ì… ë³€í™˜
    - ë¹„ì •ìƒ ê°’ì€ NaN ì²˜ë¦¬
    
    Args:
        value: ì›ë³¸ í˜¼ì¡ë„ ê°’
        
    Returns:
        ì •ë¦¬ëœ float ê°’
    """
    if pd.isna(value):
        return float('nan')
    
    # ë¬¸ìì—´ì¸ ê²½ìš° ê³µë°± ì œê±°
    if isinstance(value, str):
        value = value.strip()
        if value == '':
            return float('nan')
    
    try:
        return float(value)
    except (ValueError, TypeError):
        return float('nan')


def transform_wide_to_long(df: pd.DataFrame) -> pd.DataFrame:
    """
    ì™€ì´ë“œ í˜•íƒœì˜ ë°ì´í„°ë¥¼ ë¡± í¬ë§·ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        df: ì›ë³¸ DataFrame (ì™€ì´ë“œ í˜•íƒœ)
        
    Returns:
        ë¡± í¬ë§· DataFrame
    """
    # ê¸°ì¤€ ì»¬ëŸ¼ (ID ë³€ìˆ˜)
    id_cols = ['ìš”ì¼êµ¬ë¶„', 'í˜¸ì„ ', 'ì—­ë²ˆí˜¸', 'ì¶œë°œì—­', 'ìƒí•˜êµ¬ë¶„']
    
    # ì‹œê°„ ì»¬ëŸ¼ (ê°’ ë³€ìˆ˜) - ë‚˜ë¨¸ì§€ ëª¨ë“  ì»¬ëŸ¼
    time_cols = [col for col in df.columns if col not in id_cols]
    
    # meltë¡œ ë¡± í¬ë§· ë³€í™˜
    df_long = pd.melt(
        df,
        id_vars=id_cols,
        value_vars=time_cols,
        var_name='time_slot',
        value_name='congestion'
    )
    
    # ì»¬ëŸ¼ëª… í‘œì¤€í™”
    df_long = df_long.rename(columns={
        'ìš”ì¼êµ¬ë¶„': 'day_type',
        'í˜¸ì„ ': 'line',
        'ì—­ë²ˆí˜¸': 'station_id',
        'ì¶œë°œì—­': 'station_name',
        'ìƒí•˜êµ¬ë¶„': 'direction'
    })
    
    # ì‹œê°„ëŒ€ ì •ê·œí™”
    df_long['time_slot'] = df_long['time_slot'].apply(clean_time_slot)
    
    # í˜¼ì¡ë„ ì •ë¦¬
    df_long['congestion'] = df_long['congestion'].apply(clean_congestion)
    
    # station_idë¥¼ intë¡œ ë³€í™˜
    df_long['station_id'] = pd.to_numeric(df_long['station_id'], errors='coerce').astype('Int64')
    
    return df_long


def get_data_quality_report(df: pd.DataFrame) -> dict:
    """
    ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        df: ë¡± í¬ë§· DataFrame
        
    Returns:
        í’ˆì§ˆ ì§€í‘œ ë”•ì…”ë„ˆë¦¬
    """
    report = {}
    
    # ê¸°ë³¸ í†µê³„
    report['total_records'] = len(df)
    report['total_missing'] = df['congestion'].isna().sum()
    report['missing_pct'] = (report['total_missing'] / report['total_records'] * 100)
    
    # 0.0 ê°’ í†µê³„
    zero_count = (df['congestion'] == 0.0).sum()
    report['zero_count'] = zero_count
    report['zero_pct'] = (zero_count / report['total_records'] * 100)
    
    # í˜¼ì¡ë„ í†µê³„ (NaN ì œì™¸)
    valid_congestion = df['congestion'].dropna()
    if len(valid_congestion) > 0:
        report['min_congestion'] = valid_congestion.min()
        report['max_congestion'] = valid_congestion.max()
        report['mean_congestion'] = valid_congestion.mean()
        report['median_congestion'] = valid_congestion.median()
        
        # ì´ìƒì¹˜ í™•ì¸ (ìŒìˆ˜)
        negative_count = (valid_congestion < 0).sum()
        report['negative_count'] = negative_count
        
        # 100 ì´ˆê³¼ ê°’
        over_100_count = (valid_congestion > 100).sum()
        report['over_100_count'] = over_100_count
    else:
        report['min_congestion'] = None
        report['max_congestion'] = None
        report['mean_congestion'] = None
        report['median_congestion'] = None
        report['negative_count'] = 0
        report['over_100_count'] = 0
    
    # ìœ ë‹ˆí¬ ê°’ í†µê³„
    report['unique_stations'] = df['station_name'].nunique()
    report['unique_lines'] = df['line'].nunique()
    report['unique_day_types'] = df['day_type'].nunique()
    
    return report


@st.cache_data
def load_and_process_data(file_path: str) -> pd.DataFrame:
    """
    ë°ì´í„° ë¡œë“œì™€ ì „ì²˜ë¦¬ë¥¼ í†µí•©í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤.
    
    Args:
        file_path: CSV íŒŒì¼ ê²½ë¡œ
        
    Returns:
        ì „ì²˜ë¦¬ëœ ë¡± í¬ë§· DataFrame
    """
    # 1. ì›ë³¸ ë¡œë“œ
    df_raw = load_raw_data(file_path)
    
    # 2. ì™€ì´ë“œ â†’ ë¡± ë³€í™˜ ë° ì •ë¦¬
    df_processed = transform_wide_to_long(df_raw)
    
    return df_processed


# ============================================================================
# ë©”ì¸ UI
# ============================================================================

def main():
    st.title("ì„œìš¸ ì§€í•˜ì²  í˜¼ì¡ë„ ëŒ€ì‹œë³´ë“œ")
    st.markdown("**í˜ì´ì¦ˆ 1**: ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ í™•ì¸")
    
    # ë°ì´í„° íŒŒì¼ ê²½ë¡œ
    data_file = "ì„œìš¸êµí†µê³µì‚¬_ì§€í•˜ì² í˜¼ì¡ë„ì •ë³´_20250930.csv"
    
    # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not Path(data_file).exists():
        st.error(f"ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_file}")
        st.info("í˜„ì¬ ë””ë ‰í† ë¦¬ì— CSV íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    
    # ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
    with st.spinner("ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤..."):
        df = load_and_process_data(data_file)
    
    st.success(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ! ì´ {len(df):,}ê°œ ë ˆì½”ë“œ")
    
    # í’ˆì§ˆ ê²€ì‚¬ ë¦¬í¬íŠ¸
    with st.expander("ğŸ“Š ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸", expanded=True):
        report = get_data_quality_report(df)
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("ì´ ë ˆì½”ë“œ ìˆ˜", f"{report['total_records']:,}")
            st.metric("ìœ ë‹ˆí¬ ì—­", f"{report['unique_stations']}")
            st.metric("ìœ ë‹ˆí¬ í˜¸ì„ ", f"{report['unique_lines']}")
        
        with col2:
            st.metric("ê²°ì¸¡ì¹˜", f"{report['total_missing']:,}", 
                     f"{report['missing_pct']:.2f}%")
            st.metric("0.0 ê°’", f"{report['zero_count']:,}",
                     f"{report['zero_pct']:.2f}%")
            st.metric("ìŒìˆ˜ ê°’", f"{report['negative_count']}")
        
        with col3:
            if report['mean_congestion'] is not None:
                st.metric("í‰ê·  í˜¼ì¡ë„", f"{report['mean_congestion']:.1f}")
                st.metric("ìµœëŒ€ í˜¼ì¡ë„", f"{report['max_congestion']:.1f}")
                st.metric("100 ì´ˆê³¼ ê°’", f"{report['over_100_count']:,}")
        
        # ìƒì„¸ í†µê³„
        st.markdown("---")
        st.markdown("**ìƒì„¸ í†µê³„**")
        stats_col1, stats_col2 = st.columns(2)
        
        with stats_col1:
            st.write(f"- ìµœì†Œ í˜¼ì¡ë„: {report['min_congestion']:.1f}" if report['min_congestion'] is not None else "- ìµœì†Œ í˜¼ì¡ë„: N/A")
            st.write(f"- ì¤‘ì•™ê°’ í˜¼ì¡ë„: {report['median_congestion']:.1f}" if report['median_congestion'] is not None else "- ì¤‘ì•™ê°’ í˜¼ì¡ë„: N/A")
        
        with stats_col2:
            st.write(f"- ìš”ì¼êµ¬ë¶„ ì¢…ë¥˜: {report['unique_day_types']}")
            st.write(f"- ë°ì´í„° í’ˆì§ˆ: {'âœ… ì–‘í˜¸' if report['negative_count'] == 0 else 'âš ï¸ ìŒìˆ˜ ê°’ ì¡´ì¬'}")
    
    # ìƒ˜í”Œ ë°ì´í„° í‘œì‹œ
    st.markdown("---")
    st.subheader("ğŸ” ì „ì²˜ë¦¬ ê²°ê³¼ ìƒ˜í”Œ (20í–‰)")
    
    # ìƒ˜í”Œ 20í–‰ í‘œì‹œ
    st.dataframe(
        df.head(20),
        width='stretch',
        height=400
    )
    
    # ì „ì²´ ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì •ë³´
    with st.expander("ğŸ“‹ ë°ì´í„° ìŠ¤í‚¤ë§ˆ"):
        st.write("**ì»¬ëŸ¼ ì •ë³´:**")
        schema_df = pd.DataFrame({
            'ì»¬ëŸ¼ëª…': df.columns,
            'íƒ€ì…': [str(df[col].dtype) for col in df.columns],
            'ìƒ˜í”Œ': [str(df[col].iloc[0]) if len(df) > 0 else '' for col in df.columns]
        })
        st.dataframe(schema_df, width='stretch')


if __name__ == "__main__":
    main()
